# ðŸ“ Project Structure

Complete guide to understanding the ULTRATHINK codebase organization.

## Directory Overview

```
UltraThinking-LLM-Training/
â”œâ”€â”€ train_ultrathink.py          # Main training script (CLI)
â”œâ”€â”€ train_advanced.py             # YAML config-based training
â”œâ”€â”€ app_gradio.py                 # Web UI for inference
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Dockerfile                    # Docker container definition
â”œâ”€â”€ docker-compose.yml            # Docker orchestration
â”œâ”€â”€ setup.py                      # Package installation
â”œâ”€â”€ pytest.ini                    # Test configuration
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”‚
â”œâ”€â”€ src/                          # Core source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/                   # Model architectures
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ultrathink.py        # Main UltraThink model integration
â”‚   â”‚   â”œâ”€â”€ architecture.py      # Base transformer (GQA, RoPE, SwiGLU)
â”‚   â”‚   â”œâ”€â”€ moe_advanced.py      # Mixture-of-Experts implementation
â”‚   â”‚   â”œâ”€â”€ dynamic_reasoning.py # Dynamic Reasoning Engine (DRE)
â”‚   â”‚   â”œâ”€â”€ constitutional_ai.py # Safety and alignment
â”‚   â”‚   â””â”€â”€ multimodal.py        # Multi-modal encoders
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                     # Data loading and processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ datasets.py          # Dataset loaders (C4, WikiText, etc.)
â”‚   â”‚   â”œâ”€â”€ tokenization.py      # Tokenizer utilities
â”‚   â”‚   â”œâ”€â”€ validation.py        # Data validation
â”‚   â”‚   â””â”€â”€ preprocessing.py     # Data preprocessing
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                 # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loop.py              # Main training loop with diagnostics
â”‚   â”‚   â”œâ”€â”€ optim.py             # Optimizer configuration
â”‚   â”‚   â”œâ”€â”€ scheduler.py         # Learning rate scheduling
â”‚   â”‚   â”œâ”€â”€ rlhf_advanced.py     # RLHF 2.0 implementation
â”‚   â”‚   â”œâ”€â”€ distributed_4d.py    # 4D parallelism (DP, FSDP, TP, PP)
â”‚   â”‚   â””â”€â”€ callbacks.py         # Training callbacks
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/               # Metrics and monitoring
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Custom metrics (MoE, DRE stats)
â”‚   â”‚   â””â”€â”€ system_monitor.py    # GPU/CPU/memory monitoring
â”‚   â”‚
â”‚   â”œâ”€â”€ security/                 # Security and validation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ input_validation.py  # Input sanitization
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/               # Model evaluation
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ benchmarks.py        # Benchmark suite
â”‚       â””â”€â”€ generation.py        # Text generation utilities
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_models.py           # Model architecture tests
â”‚   â”œâ”€â”€ test_training.py         # Training loop tests
â”‚   â”œâ”€â”€ test_data.py             # Data loading tests
â”‚   â”œâ”€â”€ test_moe.py              # MoE-specific tests
â”‚   â”œâ”€â”€ test_dre.py              # DRE-specific tests
â”‚   â”œâ”€â”€ smoke_test.py            # Quick smoke test
â”‚   â””â”€â”€ integration/             # Integration tests
â”‚       â””â”€â”€ test_end_to_end.py
â”‚
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ train_tiny.yaml          # Tiny model config (CPU-friendly)
â”‚   â”œâ”€â”€ train_small.yaml         # Small model config (6-16GB GPU)
â”‚   â”œâ”€â”€ train_medium.yaml        # Medium model config (24-40GB GPU)
â”‚   â”œâ”€â”€ train_large.yaml         # Large model config (40GB+ GPU)
â”‚   â”œâ”€â”€ moe_config.yaml          # MoE-specific configuration
â”‚   â”œâ”€â”€ dre_config.yaml          # DRE-specific configuration
â”‚   â””â”€â”€ benchmark_config.yaml    # Benchmark configuration
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ inference.py             # Run inference on trained models
â”‚   â”œâ”€â”€ evaluate.py              # Evaluate model performance
â”‚   â”œâ”€â”€ profile_model.py         # Performance profiling
â”‚   â”œâ”€â”€ export_model.py          # Export to ONNX/TorchScript
â”‚   â”œâ”€â”€ cleanup.py               # Clean cache and temp files
â”‚   â””â”€â”€ download_datasets.py     # Pre-download datasets
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ README.md                # Documentation index
â”‚   â”œâ”€â”€ TRAINING_QUICKSTART.md   # 5-minute quickstart
â”‚   â”œâ”€â”€ BENCHMARKS.md            # Performance benchmarks
â”‚   â”œâ”€â”€ COMPARISON.md            # Framework comparisons
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md       # Common issues & solutions
â”‚   â”œâ”€â”€ ROADMAP.md               # Future plans
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md     # This file
â”‚   â”œâ”€â”€ datasets.md              # Dataset guide
â”‚   â”œâ”€â”€ training_small.md        # Small dataset training
â”‚   â”œâ”€â”€ training_deepspeed.md    # DeepSpeed integration
â”‚   â”œâ”€â”€ colab.md                 # Google Colab guide
â”‚   â”œâ”€â”€ colab.ipynb              # Colab notebook
â”‚   â”œâ”€â”€ faq.md                   # FAQ
â”‚   â””â”€â”€ images/                  # Documentation images
â”‚
â”œâ”€â”€ outputs/                      # Training outputs (gitignored)
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ checkpoints/                  # Model checkpoints (gitignored)
â”‚   â””â”€â”€ .gitkeep
â”‚
â””â”€â”€ mlruns/                       # MLflow tracking (gitignored)
    â””â”€â”€ .gitkeep
```

## Core Components

### 1. Training Scripts

#### `train_ultrathink.py`
Main training script with CLI arguments.

**Usage**:
```bash
python train_ultrathink.py \
  --dataset c4 \
  --hidden_size 768 \
  --num_layers 12 \
  --enable_moe
```

**Key Features**:
- Simple CLI interface
- All hyperparameters as arguments
- Good for quick experiments

#### `train_advanced.py`
YAML configuration-based training for reproducibility.

**Usage**:
```bash
python train_advanced.py --config configs/train_small.yaml
```

**Key Features**:
- YAML configuration files
- Better for production
- Easy to version control

### 2. Model Architecture (`src/models/`)

#### `ultrathink.py`
Main model class integrating all components.

```python
from src.models.ultrathink import UltraThinkModel

model = UltraThinkModel(
    vocab_size=50257,
    hidden_size=768,
    num_layers=12,
    enable_moe=True,
    enable_dre=True,
    enable_constitutional=True
)
```

#### `architecture.py`
Base transformer with modern optimizations:
- **GQA** (Grouped Query Attention) - 4x KV cache reduction
- **RoPE** (Rotary Position Embeddings) - Better sequence modeling
- **SwiGLU** - Improved activation function
- **RMSNorm** - Faster normalization
- **Flash Attention** - Memory-efficient attention

#### `moe_advanced.py`
Hierarchical Mixture-of-Experts:
- 4-level expert hierarchy (Knowledge/Skill/Meta/Safety)
- Balanced router with entropy regularization
- Load balancing losses
- Expert utilization metrics

#### `dynamic_reasoning.py`
Dynamic Reasoning Engine (DRE):
- 5 adaptive compute paths (FAST/STANDARD/EXPERT/DEEP/ULTRA_DEEP)
- Complexity scoring (9 features)
- Adaptive routing
- 40-60% compute savings

#### `constitutional_ai.py`
Safety and alignment:
- 10-category harm detection
- Self-critique module
- Revision loop
- Constitutional principles

### 3. Data Pipeline (`src/data/`)

#### `datasets.py`
Dataset loaders for:
- **C4** - Colossal Clean Crawled Corpus
- **WikiText** - Wikipedia articles
- **The Pile** - Diverse text corpus
- **OpenWebText** - Web text
- **Custom datasets** - Your own data

**Example**:
```python
from src.data.datasets import get_dataset

dataset = get_dataset(
    name='c4',
    subset='en',
    streaming=True,
    split='train'
)
```

#### `tokenization.py`
Tokenizer utilities:
- GPT-2 tokenizer (default)
- SentencePiece support
- Custom tokenizer integration

### 4. Training Infrastructure (`src/training/`)

#### `loop.py`
Main training loop with:
- Automatic mixed precision (AMP)
- Gradient accumulation
- Gradient clipping
- Checkpointing
- Metrics logging
- Diagnostic tools

#### `distributed_4d.py`
4D parallelism support:
- **Data Parallelism (DP)** - Replicate model across GPUs
- **Fully Sharded Data Parallelism (FSDP)** - Shard model parameters
- **Tensor Parallelism (TP)** - Split tensors across GPUs
- **Pipeline Parallelism (PP)** - Split layers across GPUs

### 5. Monitoring (`src/monitoring/`)

#### `metrics.py`
Custom metrics:
- MoE expert utilization
- DRE path distribution
- Routing entropy
- Load balance factors
- Gradient norms

#### `system_monitor.py`
System resource monitoring:
- GPU utilization
- Memory usage
- Disk I/O
- Network bandwidth

### 6. Configuration (`configs/`)

All configs follow this structure:

```yaml
model:
  vocab_size: 50257
  hidden_size: 768
  num_layers: 12
  num_heads: 12
  
training:
  batch_size: 4
  learning_rate: 3e-4
  num_epochs: 3
  
data:
  dataset: c4
  streaming: true
  max_seq_length: 2048
```

## File Naming Conventions

- **Scripts**: `snake_case.py` (e.g., `train_ultrathink.py`)
- **Modules**: `snake_case.py` (e.g., `dynamic_reasoning.py`)
- **Classes**: `PascalCase` (e.g., `UltraThinkModel`)
- **Functions**: `snake_case` (e.g., `get_dataset()`)
- **Constants**: `UPPER_SNAKE_CASE` (e.g., `MAX_SEQ_LENGTH`)
- **Configs**: `snake_case.yaml` (e.g., `train_small.yaml`)
- **Docs**: `UPPER_SNAKE_CASE.md` (e.g., `README.md`)

## Import Patterns

### Absolute Imports (Preferred)
```python
from src.models.ultrathink import UltraThinkModel
from src.data.datasets import get_dataset
from src.training.loop import train_model
```

### Relative Imports (Within Package)
```python
# In src/models/ultrathink.py
from .architecture import AdvancedGPTModel
from .moe_advanced import MoELayer
```

## Adding New Components

### Adding a New Model Component

1. Create file in `src/models/`:
```python
# src/models/my_component.py
import torch.nn as nn

class MyComponent(nn.Module):
    def __init__(self, config):
        super().__init__()
        # Your implementation
        
    def forward(self, x):
        # Your forward pass
        return x
```

2. Add to `src/models/__init__.py`:
```python
from .my_component import MyComponent
```

3. Integrate in `ultrathink.py`:
```python
from .my_component import MyComponent

class UltraThinkModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.my_component = MyComponent(config)
```

### Adding a New Dataset

1. Add loader in `src/data/datasets.py`:
```python
def load_my_dataset(split='train', streaming=False):
    # Your dataset loading logic
    return dataset
```

2. Register in `get_dataset()`:
```python
def get_dataset(name, **kwargs):
    if name == 'my_dataset':
        return load_my_dataset(**kwargs)
```

### Adding a New Configuration

1. Create YAML file in `configs/`:
```yaml
# configs/my_config.yaml
model:
  hidden_size: 512
  num_layers: 6

training:
  batch_size: 8
  learning_rate: 1e-4
```

2. Use with training script:
```bash
python train_advanced.py --config configs/my_config.yaml
```

## Testing Structure

### Unit Tests
Test individual components:
```python
# tests/test_models.py
def test_ultrathink_forward():
    model = UltraThinkModel(config)
    output = model(input_ids)
    assert output.shape == expected_shape
```

### Integration Tests
Test component interactions:
```python
# tests/integration/test_end_to_end.py
def test_full_training_pipeline():
    # Test complete training workflow
    pass
```

### Running Tests
```bash
# All tests
pytest

# Specific test file
pytest tests/test_models.py

# With coverage
pytest --cov=src --cov-report=html

# Smoke test (quick validation)
python tests/smoke_test.py
```

## Output Structure

### Training Outputs (`outputs/`)
```
outputs/
â””â”€â”€ experiment_name/
    â”œâ”€â”€ config.yaml              # Saved configuration
    â”œâ”€â”€ checkpoints/             # Model checkpoints
    â”‚   â”œâ”€â”€ checkpoint-1000/
    â”‚   â”œâ”€â”€ checkpoint-2000/
    â”‚   â””â”€â”€ best_model/
    â”œâ”€â”€ logs/                    # Training logs
    â”‚   â”œâ”€â”€ train.log
    â”‚   â””â”€â”€ metrics.json
    â””â”€â”€ tensorboard/             # TensorBoard logs
```

### MLflow Tracking (`mlruns/`)
```
mlruns/
â””â”€â”€ 0/                           # Experiment ID
    â””â”€â”€ run_id/                  # Run ID
        â”œâ”€â”€ metrics/             # Logged metrics
        â”œâ”€â”€ params/              # Hyperparameters
        â”œâ”€â”€ artifacts/           # Model artifacts
        â””â”€â”€ meta.yaml            # Metadata
```

## Environment Variables

Set these for customization:

```bash
# Cache directory
export HF_HOME=/path/to/cache

# MLflow tracking URI
export MLFLOW_TRACKING_URI=http://localhost:5000

# Weights & Biases
export WANDB_PROJECT=ultrathink
export WANDB_ENTITY=your_username

# CUDA devices
export CUDA_VISIBLE_DEVICES=0,1,2,3
```

## Best Practices

### Code Organization
- âœ… Keep related functionality together
- âœ… Use clear, descriptive names
- âœ… Add docstrings to all functions/classes
- âœ… Follow PEP 8 style guide

### Configuration
- âœ… Use YAML configs for reproducibility
- âœ… Version control your configs
- âœ… Document all hyperparameters

### Testing
- âœ… Write tests for new features
- âœ… Run tests before committing
- âœ… Maintain >80% code coverage

### Documentation
- âœ… Update docs when adding features
- âœ… Include usage examples
- âœ… Keep README.md current

## Quick Navigation

| Need to... | Go to... |
|-----------|----------|
| **Train a model** | `train_ultrathink.py` or `train_advanced.py` |
| **Add new architecture** | `src/models/` |
| **Add new dataset** | `src/data/datasets.py` |
| **Modify training loop** | `src/training/loop.py` |
| **Add metrics** | `src/monitoring/metrics.py` |
| **Write tests** | `tests/` |
| **Create config** | `configs/` |
| **Run inference** | `scripts/inference.py` |
| **Profile performance** | `scripts/profile_model.py` |

## Related Documentation

- **[Training Quickstart](TRAINING_QUICKSTART.md)** - Get started in 5 minutes
- **[Advanced Training Guide](../ADVANCED_TRAINING_GUIDE.md)** - Deep dive into features
- **[Contributing Guide](../CONTRIBUTING.md)** - Contribution guidelines
- **[Architecture Overview](../ARCHITECTURE_OVERVIEW.md)** - System design

---

**Questions?** Open an issue or discussion on GitHub!
