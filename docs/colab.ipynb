{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Train_UltraThink_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# UltraThink — Google Colab Training\n",
        "\n",
        "This notebook trains the UltraThink model with two ready-made configurations:\n",
        "- Local/Colab GPU (16GB+ VRAM)\n",
        "- High-End GPU (32GB+ VRAM, e.g., V100/A100)\n",
        "\n",
        "Metrics: loss, perplexity, tokens/sec are logged to console. Optional MLflow tracking is supported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpu_check"
      },
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi || echo 'No NVIDIA GPU detected'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project_setup_md"
      },
      "source": [
        "## Project Setup\n",
        "Upload your project folder (this repo) into Colab's working directory (`/content`).\n",
        "If it's in Google Drive, mount and `cd` into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mount_drive"
      },
      "source": [
        "#@title (Optional) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# After mounting, you can: %cd /content/drive/MyDrive/path/to/your/project\n",
        "# Or if you uploaded directly to /content, cd there instead\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "change_dir"
      },
      "source": [
        "#@title Change directory to your project root (edit if needed)\n",
        "# If you uploaded the repository folder named 'deep', run:\n",
        "%cd /content/deep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_deps"
      },
      "source": [
        "#@title Install dependencies\n",
        "# Prefer the project's requirements; Colab will build wheels as needed\n",
        "!pip install -q -r requirements.txt\n",
        "# Workarounds for Colab environments (safe no-ops if already satisfied)\n",
        "!pip install -q --upgrade pip setuptools wheel\n",
        "# Optional: Deepspeed is heavy; skip on Colab unless required\n",
        "# !pip install -q deepspeed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlflow_note"
      },
      "source": [
        "### MLflow (Optional)\n",
        "This project uses local MLflow (`file:./mlruns`). You can run the UI in Colab background shell and use the proxy to view it if desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "train_colab_16gb"
      },
      "source": [
        "#@title Train — Local/Colab GPU (16GB+ VRAM)\n",
        "# You can tweak perf_log_interval to control how often step loss is printed\n",
        "!python train_ultrathink.py \\\n",
        "  --dataset c4 --dataset_subset en --streaming \\\n",
        "  --tokenizer_name gpt2 --vocab_size 50257 \\\n",
        "  --hidden_size 768 --num_layers 12 --num_heads 12 --num_kv_heads 4 \\\n",
        "  --intermediate_size 3072 --max_seq_length 1024 \\\n",
        "  --activation swiglu \\\n",
        "  --dropout 0.1 --attention_dropout 0.1 \\\n",
        "  --enable_moe \\\n",
        "  --num_knowledge_experts 16 --num_skill_experts 8 \\\n",
        "  --num_meta_experts 4 --num_safety_experts 2 \\\n",
        "  --moe_top_k 2 --expert_capacity 1.25 \\\n",
        "  --enable_dre --dre_warmup_steps 1000 \\\n",
        "  --enable_constitutional \\\n",
        "  --amp_warmup_steps 500 \\\n",
        "  --batch_size 2 --gradient_accumulation_steps 64 \\\n",
        "  --learning_rate 3e-4 --weight_decay 0.1 \\\n",
        "  --adam_beta1 0.9 --adam_beta2 0.999 \\\n",
        "  --warmup_steps 5000 --num_epochs 3 \\\n",
        "  --gradient_clipping 1.0 \\\n",
        "  --use_amp --gradient_checkpointing --use_flash_attention \\\n",
        "  --eval_frequency 1 \\\n",
        "  --use_mlflow --run_name ultrathink_complete_model \\\n",
        "  --output_dir ./outputs/ultrathink_complete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "train_highend_32gb"
      },
      "source": [
        "#@title Train — High-End GPU (32GB+ VRAM: V100/A100)\n",
        "!python train_ultrathink.py \\\n",
        "  --dataset c4 --dataset_subset en --streaming \\\n",
        "  --tokenizer_name gpt2 --vocab_size 50257 \\\n",
        "  --hidden_size 2048 --num_layers 24 --num_heads 16 --num_kv_heads 8 \\\n",
        "  --intermediate_size 8192 --max_seq_length 2048 \\\n",
        "  --activation swiglu \\\n",
        "  --dropout 0.05 --attention_dropout 0.05 \\\n",
        "  --enable_moe \\\n",
        "  --num_knowledge_experts 32 --num_skill_experts 16 \\\n",
        "  --num_meta_experts 8 --num_safety_experts 4 \\\n",
        "  --moe_top_k 2 --expert_capacity 1.25 \\\n",
        "  --enable_dre --dre_warmup_steps 2000 \\\n",
        "  --enable_constitutional \\\n",
        "  --enable_multimodal \\\n",
        "  --amp_warmup_steps 1000 \\\n",
        "  --batch_size 4 --gradient_accumulation_steps 32 \\\n",
        "  --learning_rate 1e-4 --weight_decay 0.01 \\\n",
        "  --adam_beta1 0.9 --adam_beta2 0.999 \\\n",
        "  --warmup_steps 10000 --num_epochs 3 \\\n",
        "  --gradient_clipping 1.0 \\\n",
        "  --use_amp --gradient_checkpointing --use_flash_attention \\\n",
        "  --eval_frequency 2 \\\n",
        "  --use_mlflow --run_name ultrathink_large_complete \\\n",
        "  --output_dir ./outputs/ultrathink_large_complete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monitoring"
      },
      "source": [
        "## Monitoring\n",
        "Console logs will include:\n",
        "- **[step]** loss, ppl, toks/s every N steps (set by `perf_log_interval`)\n",
        "- **[train]** epoch avg_loss and avg_ppl\n",
        "- **[val]** avg_loss and avg_ppl\n",
        "\n",
        "To run MLflow UI (optional):\n",
        "```bash\n",
        "mlflow ui --host 0.0.0.0 --port 5000\n",
        "```\n",
        "Use Colab's proxy or `cloudflared` to expose the port if needed."
      ]
    }
  ]
}
